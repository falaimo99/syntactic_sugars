{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection Processor\n",
    "It takes as input a path of a json file, it loads it and extract all the possible triple from it (it works only with the given data model, in this case, a iiif manifest extracted from the Ficlit Digita Library) attaching it to a Graph database of the class Graph, extracted from the library _rdflib_. \n",
    "The classes and properties are URIs from our github repository (<link>'https://github.com/falaimo99/syntactic_sugars/'<link>).\n",
    "The collection processor, subclass '`Processor`' reads the json as a dictionary of dictionaries and throught its method `pop_graph()`('populate graph') iterates through its keys, assigning to the IDs' values of each entities the variable 'subj' and to literals and relational values the variable 'obj'. Then the URIs for properties and RDF.type manage the predicate part of the triples, adding it to the graph each time, creating a proper tuples received by the method `add()`\n",
    "It is crucial the presence of a recursive function that handles the nested part of the data (relational part), the one with 'items' as property and that allows the function to work properly.\n",
    "Another ancillary function handles the uploading of data working on the SPARQL endpoint through an instance of `SPARQLUpdateStore`, iterating through all the triples they became fully queriable through blazegraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processor import Processor\n",
    "from json import load\n",
    "from rdflib import Graph, URIRef, RDF, Literal\n",
    "from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore\n",
    "\n",
    "\n",
    "#URIRef assignments\n",
    "\n",
    "#URIRef for Classes\n",
    "EntityWithMetadata = URIRef(\"https://github.com/falaimo99/syntactic_sugars/vocabulary/EntityWithMetadata\")\n",
    "Collection = URIRef(\"https://github.com/falaimo99/syntactic_sugars/vocabulary/Collection\")\n",
    "Manifest = URIRef(\"https://github.com/falaimo99/syntactic_sugars/vocabulary/Manifest\")\n",
    "Canvas = URIRef(\"https://github.com/falaimo99/syntactic_sugars/vocabulary/Canvas\")\n",
    "\n",
    "#URIRef for Properties\n",
    "id = URIRef(\"https://github.com/falaimo99/syntactic_sugars/vocabulary/id\")\n",
    "label = URIRef(\"https://github.com/falaimo99/syntactic_sugars/vocabulary/label\")\n",
    "items_property = URIRef(\"https://github.com/falaimo99/syntactic_sugars/vocabulary/items\")\n",
    "\n",
    "\n",
    "class CollectionProcessor(Processor):\n",
    "    def __init__(self):\n",
    "        super(Processor).__init__()\n",
    "        self.dbPathorUrl = Processor.setdbPathorUrl\n",
    "\n",
    "    def uploadData(self, path):\n",
    "        db = Graph()\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = load(f)\n",
    "\n",
    "            #main function that takes the graph and the cast json file as input\n",
    "            #in order to populate it with all the triples\n",
    "            \n",
    "            def pop_graph(db, json_data):\n",
    "            \n",
    "                for key, value in json_data.items():\n",
    "                    if key == \"id\":\n",
    "                        subj = URIRef(value)\n",
    "\n",
    "                    if key == \"type\" and value == \"Collection\":\n",
    "                        obj = Collection\n",
    "                        triple = (subj, RDF.type, obj)\n",
    "                        db.add(triple)\n",
    "\n",
    "                    elif key == \"type\" and value == \"Manifest\":\n",
    "                        obj = Manifest\n",
    "                        triple = (subj, RDF.type, obj)\n",
    "                        db.add(triple)\n",
    "\n",
    "                    elif key ==\"type\" and value == \"Canvas\":\n",
    "                        obj = Canvas\n",
    "                        triple = (subj, RDF.type, obj)\n",
    "                        db.add(triple)\n",
    "\n",
    "                    if key == \"label\":\n",
    "                        for key, value in value.items():\n",
    "                            obj = Literal(value)\n",
    "                            triple = (subj, label, obj)\n",
    "                            db.add(triple)\n",
    "                    \n",
    "                    if key == \"items\":\n",
    "                        for dict in value:\n",
    "                           for int_key, int_value in dict.items():\n",
    "                               if int_key == \"id\":\n",
    "                                   obj = URIRef(int_value)\n",
    "                                   triple = (subj, items_property, obj)\n",
    "                                   db.add(triple)\n",
    "                                   pop_graph(db, dict)\n",
    "\n",
    "            # Ancillary function that uploads the data to the endpoint\n",
    "\n",
    "            def sparql_endpoint(dbPathorUrl):\n",
    "                \n",
    "                store = SPARQLUpdateStore()\n",
    "\n",
    "                endpoint = self.dbPathorUrl\n",
    "                \n",
    "                store.open((endpoint, endpoint))\n",
    "                \n",
    "                for triple in db.triples((None, None, None)):\n",
    "                    store.add(triple)\n",
    "\n",
    "                store.close()\n",
    "\n",
    "\n",
    "            pop_graph(db, json_data)\n",
    "            sparql_endpoint(self.dbPathorUrl)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "In the cell below there's the execution of the whole algorithm to set the endpoint and upload the data to it through http requests.\n",
    "It follows the guidelines that state how to execute the final program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_proc = CollectionProcessor()\n",
    "col_proc.setdbPathorUrl(\"http://127.0.0.1:9999/blazegraph/sparql\")\n",
    "col_proc.getdbPathorUrl()\n",
    "col_proc.uploadData(\"data/collection-1.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
